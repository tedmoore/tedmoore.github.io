<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>research &amp; software on Ted Moore | Composer, Improviser, Intermedia Artist</title><link>https://tedmoore.github.io/research/</link><description>Recent content in research &amp; software on Ted Moore | Composer, Improviser, Intermedia Artist</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Ted Moore. All Rights Reserved.</copyright><atom:link href="https://tedmoore.github.io/research/index.xml" rel="self" type="application/rss+xml"/><item><title>DJII</title><link>https://tedmoore.github.io/research/djii/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/djii/</guid><description>Pronounced like the letter &amp;ldquo;G&amp;rdquo;
DJII was designed by Dana Jessen and Ted Moore during 2021-2022 and coded by Ted Moore in SuperCollider. The software is designed to be used by an improvising solo musician as supporting electronics material.
The modular GUI design allows for intuitive exploration of sound possibilities including flexible matrix-based routing. Software-wide state save and recall enables performer navigation through different preplanned sections of a performance.</description></item><item><title>FluCoMa</title><link>https://tedmoore.github.io/research/flucoma/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/flucoma/</guid><description>During the 2021-2022 academic year I served as a postdoctoral Research Fellow in Creative Coding at the University of Huddersfield CeReNeM working on the project Fluid Corpus Manipulation (&amp;ldquo;FluCoMa&amp;rdquo;).
FluCoMa enables techno-fluent musicians to integrate machine listening and machine learning in their creative practice within Max, SuperCollider, and Pure Data. The toolkit offers tools to separate audio into component parts including slicers and spectral decomposition algorithms, audio analysis tools to describe audio components as analytical and statistical representations, data analysis and machine learning algorithms for pattern detection and expressive dataset browsing, and audio morphing and hybridization algorithms for audio remixing, interpolating, and variation-making.</description></item><item><title>Microtonal Keyboard</title><link>https://tedmoore.github.io/research/microtonal-keyboard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/microtonal-keyboard/</guid><description> Commissioned by composer Katie Balch, this application allows for microtonal adjustment of each note +/-50 cents. It can be connected to and played by a MIDI keyboard as well as with a QWERTY keyboard for quick and easy use. Tunings can be saved as files and recalled for continued use on multiple projects.
github</description></item><item><title>Module Tensor</title><link>https://tedmoore.github.io/research/module-tensor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/module-tensor/</guid><description>Module Tensor is the custom software I coded in SuperCollider and use to improvise on live electronics. It is based on a system of routing audio through processing modules and maximal flexibility of control with any MIDI or OSC devices. The primary use is live laptop improvisation, but it is also used as a framework for executing performances of my compositions. The conceptual structuring of this software is based on the research of laptop improviser Sam Pluta.</description></item><item><title>Serge Modular Archive Instrument</title><link>https://tedmoore.github.io/research/serge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/serge/</guid><description>check out the GitHub Repo for this project.
The Serge Modular Archive Instrument (created in collaboration with Jean Brazeau) is a sample-based computer emulation of selected patches on the vintage Serge Modular instrument that is housed at Simon Frasier University in Vancouver, Canada. The project is conceived of as both an instrument for sonic exploration and an archive of the sound worlds made by this 50+ year old instrument, including (or highlighting) all of the idiosyncrasies it has accumulated over the years.</description></item></channel></rss>