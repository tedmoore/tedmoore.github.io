<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Ted Moore | Composer, Improviser, Intermedia Artist</title><link>https://tedmoore.github.io/tags/machine-learning/</link><description>Recent content in machine learning on Ted Moore | Composer, Improviser, Intermedia Artist</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Ted Moore. All Rights Reserved.</copyright><atom:link href="https://tedmoore.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>alloy</title><link>https://tedmoore.github.io/works/alloy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/alloy/</guid><description>alloy uses the same feedback cymbal setup as in my solo work it teaches us that it doesn&amp;rsquo;t exist, however this duo also includes an instrument that can produce multiphonics. During performance, the feedback cymbal&amp;rsquo;s audio is analyzed for chroma and in real-time compared to recordings of the instrumetalist&amp;rsquo;s multiphonics (that were recorded and analyzed earlier). The multiphonic most similar to the current cymbal timbre is displayed on a screen for the instrumentalist, who may choose to either play the displayed multiphonic or deviate from it, as the musical moment offers.</description></item><item><title>feed</title><link>https://tedmoore.github.io/works/feed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feed/</guid><description>feed was created in collaboration with bassoonist Ben Roidl-Ward for Experimental Sound Studio&amp;rsquo;s Oscillation Series.
feed integrates multiple modes of real-time lighting control using custom tools that implement DMX parameterization, machine learning, music information retrieval, and Reaper sequencer integration. My DMX parameter control system is a family of OOP classes written in SuperCollider that can be implemented with any DMX compatible lights. It allows for user-defined parameter naming and contains built-in timed fades, LFO modulation, control bus following (for audio reactivity), and user-defined function control of individual parameters.</description></item><item><title>FluCoMa</title><link>https://tedmoore.github.io/research/flucoma/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/flucoma/</guid><description>During the 2021-2022 academic year I served as a postdoctoral Research Fellow in Creative Coding at the University of Huddersfield CeReNeM working on the project Fluid Corpus Manipulation (&amp;ldquo;FluCoMa&amp;rdquo;).
FluCoMa enables techno-fluent musicians to integrate machine listening and machine learning in their creative practice within Max, SuperCollider, and Pure Data. The toolkit offers tools to separate audio into component parts including slicers and spectral decomposition algorithms, audio analysis tools to describe audio components as analytical and statistical representations, data analysis and machine learning algorithms for pattern detection and expressive dataset browsing, and audio morphing and hybridization algorithms for audio remixing, interpolating, and variation-making.</description></item><item><title>hollow</title><link>https://tedmoore.github.io/works/hollow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/hollow/</guid><description>hollow was created in collaboration with saxophonist Kyle Hutchins and is featured on Binary Canary&amp;rsquo;s album iterative systems out on Carrier Records.
Three large PVC tubes (4 inches in diameter and between 7 and 10 feet long–they can be seen in the video) are amplified by placing a microphone on one end and a speaker on the other. The feedback this creates is stable only at the resonant frequencies of the tube.</description></item><item><title>Module Tensor</title><link>https://tedmoore.github.io/research/module-tensor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/module-tensor/</guid><description>Module Tensor is the custom software I coded in SuperCollider and use to improvise on live electronics. It is based on a system of routing audio through processing modules and maximal flexibility of control with any MIDI or OSC devices. The primary use is live laptop improvisation, but it is also used as a framework for executing performances of my compositions. The conceptual structuring of this software is based on the research of laptop improviser Sam Pluta.</description></item><item><title>noise/gate</title><link>https://tedmoore.github.io/works/noise-gate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/noise-gate/</guid><description> Composed for Giacomo Piermatti of Ensemble Suono Giallo for ilSuono Contemporary Music Week 2021. Città di Castello, Italy.
full score</description></item><item><title>quartet</title><link>https://tedmoore.github.io/works/quartet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/quartet/</guid><description>Musicologist Jacob Hart has written a nice article about this work. Read it here.
created with the [Switch~ Ensemble]:
Zach Sheets, flute
T.J. Borden, cello
Wei-Han Wu, piano
Megan Arns, percussion
quartet is a remote collaboration between myself and the [Switch~ Ensemble] designed to engage with the added technological mediation at play during the pandemic. The sonic source material of quartet is about two minutes of eurorack synthesizer recordings transcribed for the [Switch~ Ensemble] to record.</description></item><item><title>Serge Modular Archive Instrument</title><link>https://tedmoore.github.io/research/serge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/serge/</guid><description>The Serge Modular Archive Instrument (created in collaboration with Jean Brazeau) is a sample-based computer emulation of selected patches on the vintage Serge Modular instrument that is housed at Simon Frasier University in Vancouver, Canada. The project is conceived of as both an instrument for sonic exploration and an archive of the sound worlds made by this 50+ year old instrument, including (or highlighting) all of the idiosyncrasies it has accumulated over the years.</description></item><item><title>shadow</title><link>https://tedmoore.github.io/works/shadow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/shadow/</guid><description>shadow exists as both a solo version for no-input mixer and lights (performed at Omaha Under the Radar in 2018) and as a duo with saxophone. In this video, shadow was played as one movement of a longer performance on the Frequency Series at Constellation in Chicago.
The sounds of the no-input mixer are analyzed in real-time using timbral descriptors, which are then sent to a neural network for classification into one of four categories: distorted noise, high squeal, low impulses, or quiet sustained noise.</description></item></channel></rss>