<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Ted Moore | Composer, Improviser, Intermedia Artist</title><link>https://tedmoore.github.io/tags/machine-learning/</link><description>Recent content in machine learning on Ted Moore | Composer, Improviser, Intermedia Artist</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Ted Moore. All Rights Reserved.</copyright><atom:link href="https://tedmoore.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>alloy</title><link>https://tedmoore.github.io/works/alloy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/alloy/</guid><description>alloy uses the same feedback cymbal setup as in my solo work it teaches us that it doesn&amp;rsquo;t exist, however this duo also includes an instrument that can produce multiphonics. During performance, the feedback cymbal&amp;rsquo;s audio is analyzed for chroma and in real-time compared to recordings of the instrumetalist&amp;rsquo;s multiphonics (that were recorded and analyzed earlier). The multiphonic most similar to the current cymbal timbre is displayed on a screen for the instrumentalist, who may choose to either play the displayed multiphonic or deviate from it, as the musical moment offers.</description></item><item><title>arco</title><link>https://tedmoore.github.io/works/arco/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/arco/</guid><description>arco was motivated by an suggestion from violinist Marco Fusi to create a solo violin version of my work triangle for string quartet and tape. I liked the idea but felt that it would make more sense alongside additional movements to provide some context and commentary on this solo version. arco is a five movement work of which the solo version of triangle is movement four. I also created video designs to accompany the violinist and tape parts.</description></item><item><title>feed</title><link>https://tedmoore.github.io/works/feed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feed/</guid><description>feed was created in collaboration with bassoonist Ben Roidl-Ward for Experimental Sound Studio&amp;rsquo;s Oscillation Series.
feed integrates multiple modes of real-time lighting control using custom tools that implement DMX parameterization, machine learning, music information retrieval, and Reaper sequencer integration. My DMX parameter control system is a family of OOP classes written in SuperCollider that can be implemented with any DMX compatible lights. It allows for user-defined parameter naming and contains built-in timed fades, LFO modulation, control bus following (for audio reactivity), and user-defined function control of individual parameters.</description></item><item><title>FluCoMa</title><link>https://tedmoore.github.io/research/flucoma/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/flucoma/</guid><description>Registration open for the FluCoMa Workshop Summer 2024
During the 2021-2022 academic year I served as a postdoctoral Research Fellow in Creative Coding at the University of Huddersfield CeReNeM working on the project Fluid Corpus Manipulation (&amp;ldquo;FluCoMa&amp;rdquo;).
FluCoMa enables techno-fluent musicians to integrate machine listening and machine learning in their creative practice within Max, SuperCollider, and Pure Data. The toolkit offers tools to separate audio into component parts including slicers and spectral decomposition algorithms, audio analysis tools to describe audio components as analytical and statistical representations, data analysis and machine learning algorithms for pattern detection and expressive dataset browsing, and audio morphing and hybridization algorithms for audio remixing, interpolating, and variation-making.</description></item><item><title>hollow</title><link>https://tedmoore.github.io/works/hollow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/hollow/</guid><description>hollow was created in collaboration with saxophonist Kyle Hutchins and is featured on Binary Canary&amp;rsquo;s album iterative systems out on Carrier Records.
Three large PVC tubes (4 inches in diameter and between 7 and 10 feet long–they can be seen in the video) are amplified by placing a microphone on one end and a speaker on the other. The feedback this creates is stable only at the resonant frequencies of the tube.</description></item><item><title>Module Tensor</title><link>https://tedmoore.github.io/research/module-tensor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/module-tensor/</guid><description>Module Tensor is the custom software I coded in SuperCollider and use to improvise on live electronics. It is based on a system of routing audio through processing modules and maximal flexibility of control with any MIDI or OSC devices. The primary use is live laptop improvisation, but it is also used as a framework for executing performances of my compositions. The conceptual structuring of this software is based on the research of laptop improviser Sam Pluta.</description></item><item><title>nand</title><link>https://tedmoore.github.io/works/nand/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/nand/</guid><description>nand was premiered by the Splice Ensemble at their 2023 Splice Festival in Boston. nand is based on the timbre and rhythmic gating of the NAND-gate feedback circuit described by Nick Collins in Handmade Electronic Music. Even though the system is quite simple (producing repeating phrases consisting of square waves, filtered noise, and silence), each gesture has microvariations that increase the entropy and attract my attention endlessly. My favorite timbres from this circuit occur while parameters are being changed–when capacitors are firing at surprising times, before they can settle into a stasis.</description></item><item><title>noise/gate</title><link>https://tedmoore.github.io/works/noise-gate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/noise-gate/</guid><description> Composed for Giacomo Piermatti of Ensemble Suono Giallo for ilSuono Contemporary Music Week 2021. Città di Castello, Italy.
full score</description></item><item><title>quartet</title><link>https://tedmoore.github.io/works/quartet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/quartet/</guid><description>Jacob Hart has written a nice article about this work. Read it here._** -- created with the [Switch~ Ensemble]:
Zach Sheets, flute
T.J. Borden, cello
Wei-Han Wu, piano
Megan Arns, percussion
quartet is a remote collaboration between myself and the [Switch~ Ensemble] designed to engage with the added technological mediation at play during the pandemic. The sonic source material of quartet is about two minutes of eurorack synthesizer recordings transcribed for the [Switch~ Ensemble] to record.</description></item><item><title>saccades</title><link>https://tedmoore.github.io/works/saccades/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/saccades/</guid><description>A “saccade” is a rapid movement of the eyeball between two fixed focal points. During this brief moment, the brain hides this blurry motion from our perception. Once a saccade motion has begun, the destination cannot change, meaning that if the target of focus disappears the viewer won’t know until the saccade completes. If the field of vision is changing too quickly, the saccades may never be able to arrive at and focus on a target, instead, the objects in view are only perceived through peripheral vision.</description></item><item><title>Serge Modular Archive Instrument</title><link>https://tedmoore.github.io/research/serge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/research/serge/</guid><description>check out the GitHub Repo for this project.
The Serge Modular Archive Instrument (created in collaboration with Jean Brazeau) is a sample-based computer emulation of selected patches on the vintage Serge Modular instrument that is housed at Simon Frasier University in Vancouver, Canada. The project is conceived of as both an instrument for sonic exploration and an archive of the sound worlds made by this 50+ year old instrument, including (or highlighting) all of the idiosyncrasies it has accumulated over the years.</description></item><item><title>shadow</title><link>https://tedmoore.github.io/works/shadow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/shadow/</guid><description>shadow exists as both a solo version for no-input mixer and lights (performed at Omaha Under the Radar in 2018) and as a duo with saxophone. In this video, shadow was played as one movement of a longer performance on the Frequency Series at Constellation in Chicago.
The sounds of the no-input mixer are analyzed in real-time using timbral descriptors, which are then sent to a neural network for classification into one of four categories: distorted noise, high squeal, low impulses, or quiet sustained noise.</description></item></channel></rss>