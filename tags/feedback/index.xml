<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>feedback on Ted Moore | Composer, Improviser, Intermedia Artist</title><link>https://tedmoore.github.io/tags/feedback/</link><description>Recent content in feedback on Ted Moore | Composer, Improviser, Intermedia Artist</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Ted Moore. All Rights Reserved.</copyright><atom:link href="https://tedmoore.github.io/tags/feedback/index.xml" rel="self" type="application/rss+xml"/><item><title>alloy</title><link>https://tedmoore.github.io/works/alloy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/alloy/</guid><description>alloy uses the same feedback cymbal setup as in my solo work it teaches us that it doesn&amp;rsquo;t exist, however this duo also includes an instrument that can produce multiphonics. During performance, the feedback cymbal&amp;rsquo;s audio is analyzed for chroma and in real-time compared to recordings of the instrumetalist&amp;rsquo;s multiphonics (that were recorded and analyzed earlier). The multiphonic most similar to the current cymbal timbre is displayed on a screen for the instrumentalist, who may choose to either play the displayed multiphonic or deviate from it, as the musical moment offers.</description></item><item><title>APPETITE</title><link>https://tedmoore.github.io/works/appetite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/appetite/</guid><description>Created in collaboration with theater artist Charles Campbell of Skewed Visions.
​APPETITE uses the principle of feedback (audio, video, and cultural) to create environments that, while structured and intentional, are open, unpredictable, and greater than the elements used in their construction.
The texts in APPETITE use Chris Marker&amp;rsquo;s influential 1962 sci-fi/experimental film, La Jetée as a starting point. Marker&amp;rsquo;s time-travel love-story film is almost entirely made up of a sequence of still images with voice-over narration.</description></item><item><title>circle</title><link>https://tedmoore.github.io/works/circle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/circle/</guid><description> live performance recorded on April 5, 2018 by Spektral Quartet University of Chicago Chicago, IL
full score</description></item><item><title>column</title><link>https://tedmoore.github.io/works/column/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/column/</guid><description>The spatialized sounds used were designed using custom spatialization algorithms (tuned to the space) and custom sound design software created in SuperCollider.
The DMX lights were composed and sequenced using a custom protocol between Reaper and SuperCollider.
This is a stereo mixdown.</description></item><item><title>eclipse</title><link>https://tedmoore.github.io/works/eclipse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/eclipse/</guid><description>eclipse was commissioned by Skewed Visions, an experimental theater company in Minneapolis. The piece includes live audio processing using SuperCollider, as well as live visuals created with Processing. The visuals are controlled by the audio of the performer, giving the freedom to improvise within the structure specified by the composer, but keeping the visual and musical elements intimately connected through gesture.</description></item><item><title>FEATHERMUCKER</title><link>https://tedmoore.github.io/works/feathermucker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feathermucker/</guid><description>FEATHERMUCKER by Ted Moore featuring The Dream Songs Project with text by Timothy Otte text by Timothy Otte
Commissioned by The Dream Songs Project
Over the work’s 50 minute duration, Timothy Otte’s text sets a crumbled, post-apocalyptic world in which he describes the creative process of making idiosyncratic meaning where objective meaning cannot be found. Musically, FEATHERMUCKER is a combination of folk, experimental, and electronic music; cinematic sound fx; and sound art installation.</description></item><item><title>feed</title><link>https://tedmoore.github.io/works/feed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feed/</guid><description>feed was created in collaboration with bassoonist Ben Roidl-Ward for Experimental Sound Studio&amp;rsquo;s Oscillation Series.
feed integrates multiple modes of real-time lighting control using custom tools that implement DMX parameterization, machine learning, music information retrieval, and Reaper sequencer integration. My DMX parameter control system is a family of OOP classes written in SuperCollider that can be implemented with any DMX compatible lights. It allows for user-defined parameter naming and contains built-in timed fades, LFO modulation, control bus following (for audio reactivity), and user-defined function control of individual parameters.</description></item><item><title>feedback V</title><link>https://tedmoore.github.io/works/feedback-v/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feedback-v/</guid><description>feedback V is part of a series of works that use feedback systems in various ways. The feedback in this performance is entirely acoustic and the nodes in the feedback path are the humans in the ensemble. All the performers make quiet sparse sounds throughout the performance, listening to each other in the room and responding differently at different times. At first a series of negative feedback responses regulate the distance of the performers to each other.</description></item><item><title>fold</title><link>https://tedmoore.github.io/works/fold/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/fold/</guid><description>fold was commissioned to reflect the theme of &amp;ldquo;Location Sharing&amp;rdquo; for the 2023 Browser Sound Festival in Stuttgart. The ensemble in residence for the festival was a pianist who is in the room during the performance and a saxophonist and bass clarinetist who are remote (as in, in other countries). I chose to reflect the theme of &amp;ldquo;location sharing&amp;rdquo; by using audio feedback to &amp;ldquo;sound out&amp;rdquo; the resonant frequencies of the remote performers&amp;rsquo; locations.</description></item><item><title>hollow</title><link>https://tedmoore.github.io/works/hollow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/hollow/</guid><description>hollow was created in collaboration with saxophonist Kyle Hutchins and is featured on Binary Canary&amp;rsquo;s album iterative systems out on Carrier Records.
Three large PVC tubes (4 inches in diameter and between 7 and 10 feet long–they can be seen in the video) are amplified by placing a microphone on one end and a speaker on the other. The feedback this creates is stable only at the resonant frequencies of the tube.</description></item><item><title>it teaches us that it doesn't exist</title><link>https://tedmoore.github.io/works/it-teaches-us/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/it-teaches-us/</guid><description>commissioned by percussionist Jeremy Johnston
it teaches us that it doesn&amp;rsquo;t exist creates an audio feedback loop by attaching a transducer to a suspended cymbal. The transducer agitates the cymbal with whatever audio signal is coming in through the microphone, which, when placed over the cymbal amplifies the sounds of the cymbal, agitating it further, creating a positive feedback loop. Moving the microphone over different parts of the cymbal and at different distances and angles creates different feedback tones and dynamics.</description></item><item><title>leviathan</title><link>https://tedmoore.github.io/works/leviathan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/leviathan/</guid><description>commissioned by Spitting Image Collective
composed for Sarah Porwoll-Lee
leviathan embodies the sonic world that one might hear in a littoral cave. The work was inspired by An Uaimh Bhinn, a cave on the Scottish coast famous for its unique harmonic resonances. The reverb used in the piece is modeled on the impulse response of a cavern; the vases serve as harmonic resonators through which many sounds are processed live, including the swell of ocean waves and the bass clarinet.</description></item><item><title>nand</title><link>https://tedmoore.github.io/works/nand/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/nand/</guid><description>nand will be premiered by the Splice Ensemble at their 2023 Splice Festival in Boston. My recent obsession has been the timbre and rhythmic gating of the NAND-gate feedback circuit described by Nick Collins in Handmade Electronic Music. Even though the system is quite simple (producing repeating phrases consisting of square waves, filtered noise, and silence), each gesture has microvariations that increase the entropy and attract my attention endlessly. My favorite timbres from this circuit occur while parameters are being changed–when capacitors are firing at surprising times, before they can settle into a stasis.</description></item><item><title>saccades</title><link>https://tedmoore.github.io/works/saccades/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/saccades/</guid><description>A “saccade” is a rapid movement of the eyeball between two fixed focal points. During this brief moment, the brain hides this blurry motion from our perception. Once a saccade motion has begun, the destination cannot change, meaning that if the target of focus disappears the viewer won’t know until the saccade completes. If the field of vision is changing too quickly, the saccades may never be able to arrive at and focus on a target, instead, the objects in view are only perceived through peripheral vision.</description></item><item><title>shadow</title><link>https://tedmoore.github.io/works/shadow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/shadow/</guid><description>shadow exists as both a solo version for no-input mixer and lights (performed at Omaha Under the Radar in 2018) and as a duo with saxophone. In this video, shadow was played as one movement of a longer performance on the Frequency Series at Constellation in Chicago.
The sounds of the no-input mixer are analyzed in real-time using timbral descriptors, which are then sent to a neural network for classification into one of four categories: distorted noise, high squeal, low impulses, or quiet sustained noise.</description></item></channel></rss>