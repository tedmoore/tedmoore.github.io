<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>intermedia on Ted Moore | Composer, Improviser, Intermedia Artist</title><link>https://tedmoore.github.io/tags/intermedia/</link><description>Recent content in intermedia on Ted Moore | Composer, Improviser, Intermedia Artist</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Ted Moore. All Rights Reserved.</copyright><atom:link href="https://tedmoore.github.io/tags/intermedia/index.xml" rel="self" type="application/rss+xml"/><item><title>Aluminum Forest</title><link>https://tedmoore.github.io/works/aluminum-forest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/aluminum-forest/</guid><description>created in collaboration with Katherine Balch.
Scores of hand-crafted aluminum chimes are placed all throughout the garden. Each is independently agitated by a small DC motor creating varying gestures, trajectories, and timbres. Motion sensors (connected to the motors through a small Arduino controller) trigger added agitation, acknowledging audiences presence and allowing them to participate in shaping the sonic environment. The Arduinos are also be controlled via WiFi enabling the entire system of chimes to be a performative space creating motions and gestures of sound that encompass the garden and can adapt to different configuration of chimes and installation sites.</description></item><item><title>APPETITE</title><link>https://tedmoore.github.io/works/appetite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/appetite/</guid><description>Created in collaboration with theater artist Charles Campbell of Skewed Visions.
​APPETITE uses the principle of feedback (audio, video, and cultural) to create environments that, while structured and intentional, are open, unpredictable, and greater than the elements used in their construction.
The texts in APPETITE use Chris Marker&amp;rsquo;s influential 1962 sci-fi/experimental film, La Jetée as a starting point. Marker&amp;rsquo;s time-travel love-story film is almost entirely made up of a sequence of still images with voice-over narration.</description></item><item><title>APSIS</title><link>https://tedmoore.github.io/works/apsis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/apsis/</guid><description>composed for and premiered by Strains New Music Ensemble
performance score
The video design was created mostly using Processing</description></item><item><title>circle</title><link>https://tedmoore.github.io/works/circle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/circle/</guid><description> live performance recorded on April 5, 2018 by Spektral Quartet University of Chicago Chicago, IL
full score</description></item><item><title>column</title><link>https://tedmoore.github.io/works/column/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/column/</guid><description>The spatialized sounds used were designed using custom spatialization algorithms (tuned to the space) and custom sound design software created in SuperCollider.
The DMX lights were composed and sequenced using a custom protocol between Reaper and SuperCollider.
This is a stereo mixdown.</description></item><item><title>eclipse</title><link>https://tedmoore.github.io/works/eclipse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/eclipse/</guid><description>eclipse was commissioned by Skewed Visions, an experimental theater company in Minneapolis. The piece includes live audio processing using SuperCollider, as well as live visuals created with Processing. The visuals are controlled by the audio of the performer, giving the freedom to improvise within the structure specified by the composer, but keeping the visual and musical elements intimately connected through gesture.</description></item><item><title>feed</title><link>https://tedmoore.github.io/works/feed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feed/</guid><description>feed was created in collaboration with bassoonist Ben Roidl-Ward for Experimental Sound Studio&amp;rsquo;s Oscillation Series.
feed integrates multiple modes of real-time lighting control using custom tools that implement DMX parameterization, machine learning, music information retrieval, and Reaper sequencer integration. My DMX parameter control system is a family of OOP classes written in SuperCollider that can be implemented with any DMX compatible lights. It allows for user-defined parameter naming and contains built-in timed fades, LFO modulation, control bus following (for audio reactivity), and user-defined function control of individual parameters.</description></item><item><title>fold</title><link>https://tedmoore.github.io/works/fold/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/fold/</guid><description>Read DigiScore's analysis of fold
fold was commissioned to reflect the theme of &amp;ldquo;Location Sharing&amp;rdquo; for the 2023 Browser Sound Festival in Stuttgart. The ensemble in residence for the festival was a pianist who is in the room during the performance and a saxophonist and bass clarinetist who are remote (as in, in other countries). I chose to reflect the theme of &amp;ldquo;location sharing&amp;rdquo; by using audio feedback to &amp;ldquo;sound out&amp;rdquo; the resonant frequencies of the remote performers&amp;rsquo; locations.</description></item><item><title>for line upon line</title><link>https://tedmoore.github.io/works/for-line-upon-line/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/for-line-upon-line/</guid><description>My friends at line upon line percussion asked me to come up with an idea for a short piece that could be created collaboratively with them during the COVID time of physical distancing. In turn, I asked for videos of them making a collection of sounds that I could then combine into some groovy video thing.
The videos are played using custom software in c++ created with openframeworks, however all of the sequencing was done with patterns in SuperCollider.</description></item><item><title>nand</title><link>https://tedmoore.github.io/works/nand/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/nand/</guid><description>nand will be premiered by the Splice Ensemble at their 2023 Splice Festival in Boston. My recent obsession has been the timbre and rhythmic gating of the NAND-gate feedback circuit described by Nick Collins in Handmade Electronic Music. Even though the system is quite simple (producing repeating phrases consisting of square waves, filtered noise, and silence), each gesture has microvariations that increase the entropy and attract my attention endlessly. My favorite timbres from this circuit occur while parameters are being changed–when capacitors are firing at surprising times, before they can settle into a stasis.</description></item><item><title>noise/gate</title><link>https://tedmoore.github.io/works/noise-gate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/noise-gate/</guid><description> Composed for Giacomo Piermatti of Ensemble Suono Giallo for ilSuono Contemporary Music Week 2021. Città di Castello, Italy.
full score</description></item><item><title>quartet</title><link>https://tedmoore.github.io/works/quartet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/quartet/</guid><description>Musicologist Jacob Hart has written a nice article about this work. Read it here.
created with the [Switch~ Ensemble]:
Zach Sheets, flute
T.J. Borden, cello
Wei-Han Wu, piano
Megan Arns, percussion
quartet is a remote collaboration between myself and the [Switch~ Ensemble] designed to engage with the added technological mediation at play during the pandemic. The sonic source material of quartet is about two minutes of eurorack synthesizer recordings transcribed for the [Switch~ Ensemble] to record.</description></item><item><title>saccades</title><link>https://tedmoore.github.io/works/saccades/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/saccades/</guid><description>A “saccade” is a rapid movement of the eyeball between two fixed focal points. During this brief moment, the brain hides this blurry motion from our perception. Once a saccade motion has begun, the destination cannot change, meaning that if the target of focus disappears the viewer won’t know until the saccade completes. If the field of vision is changing too quickly, the saccades may never be able to arrive at and focus on a target, instead, the objects in view are only perceived through peripheral vision.</description></item><item><title>Solstice Orrery</title><link>https://tedmoore.github.io/works/solstice-orrery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/solstice-orrery/</guid><description>Music composed by Scott Miller: Solstice Orrery on Raba (New Focus Recordings fcr198)
Video design by Ted Moore
Scott asked me to create a video design for this track (Solstice Orrery) on his New Focus release, Raba. An &amp;ldquo;orrery&amp;rdquo; is a mechanical model of the solar system (as can be heard in the music). I took inspiration from the title and used/created images of the sun in various renderings. Scott sent me the individual stems of the audio so I could analyze them and make a video that could respond to the different parts of the sounds in different ways.</description></item><item><title>still motion</title><link>https://tedmoore.github.io/works/still-motion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/still-motion/</guid><description>Commissioned by and composed for percussionist Patti Cudd with support from MacPhail Center for Music and the McKnight Foundation.
still motion uses live audio and video sampling of the performing percussionist, the projection of which creates a counterpoint to the live performer. All of the sampling is done with an openFrameworks program coded in C++.
full score Contact me for the software download.</description></item><item><title>still motion b</title><link>https://tedmoore.github.io/works/still-motion-b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/still-motion-b/</guid><description>still motion b uses live audio and video sampling of the performer&amp;rsquo;s mouth, the projection of which creates a counterpoint to the live performance. All of the sampling is done with an openFrameworks program coded in C++.
Contact me for the software download.</description></item><item><title>tap</title><link>https://tedmoore.github.io/works/tap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/tap/</guid><description>Commissioned by line upon line percussion
recorded at UT Austin, January 12, 2019
Composing tap began by recording many sounds, gestures, and passages on my eurorack modular synthesizer and then organizing these recordings into a tape part for the piece. I then transcribed the rhythms and timbres of the tape part to create a tight synchronization between the the tape and percussion parts played by the ensemble. The video and lights were then composed to add to the intense synchrony.</description></item><item><title>transliteration</title><link>https://tedmoore.github.io/works/transliteration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/transliteration/</guid><description>My transliteration project is a book series that visualizes digital audio using different representations, such as waveforms, binary data, or fourier transformations. These images feel like a microscope and a pause button, allowing us to sit with one moment in time, look at it very closely, in a new way, and appreciate the specificity, detail, and care it can convey.</description></item></channel></rss>