<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>lights on Ted Moore | Composer, Improviser, Intermedia Artist</title><link>https://tedmoore.github.io/tags/lights/</link><description>Recent content in lights on Ted Moore | Composer, Improviser, Intermedia Artist</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Ted Moore. All Rights Reserved.</copyright><atom:link href="https://tedmoore.github.io/tags/lights/index.xml" rel="self" type="application/rss+xml"/><item><title>attackSUSTAINrelease</title><link>https://tedmoore.github.io/works/attacksustainrelease/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/attacksustainrelease/</guid><description>At the pace of one taking deep breaths, brown noise swells in and out of each suspended raw speaker cone in an unpredictable pattern. With it, the water in the cones agitate and reflect light into shimmering patterns on the walls and ceiling. The minimalist presentation draws a strong causal relationship between all of the elements in the room: sound, water, light, and the physical functionality of speakers.</description></item><item><title>circle</title><link>https://tedmoore.github.io/works/circle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/circle/</guid><description> live performance recorded on April 5, 2018 by Spektral Quartet University of Chicago Chicago, IL
full score</description></item><item><title>column</title><link>https://tedmoore.github.io/works/column/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/column/</guid><description>The spatialized sounds used were designed using custom spatialization algorithms (tuned to the space) and custom sound design software created in SuperCollider.
The DMX lights were composed and sequenced using a custom protocol between Reaper and SuperCollider.
This is a stereo mixdown.</description></item><item><title>feed</title><link>https://tedmoore.github.io/works/feed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/feed/</guid><description>feed was created in collaboration with bassoonist Ben Roidl-Ward for Experimental Sound Studio&amp;rsquo;s Oscillation Series.
feed integrates multiple modes of real-time lighting control using custom tools that implement DMX parameterization, machine learning, music information retrieval, and Reaper sequencer integration. My DMX parameter control system is a family of OOP classes written in SuperCollider that can be implemented with any DMX compatible lights. It allows for user-defined parameter naming and contains built-in timed fades, LFO modulation, control bus following (for audio reactivity), and user-defined function control of individual parameters.</description></item><item><title>hollow</title><link>https://tedmoore.github.io/works/hollow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/hollow/</guid><description>hollow was created in collaboration with saxophonist Kyle Hutchins and is featured on Binary Canary&amp;rsquo;s album iterative systems out on Carrier Records.
Three large PVC tubes (4 inches in diameter and between 7 and 10 feet longâ€“they can be seen in the video) are amplified by placing a microphone on one end and a speaker on the other. The feedback this creates is stable only at the resonant frequencies of the tube.</description></item><item><title>shadow</title><link>https://tedmoore.github.io/works/shadow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/shadow/</guid><description>shadow exists as both a solo version for no-input mixer and lights (performed at Omaha Under the Radar in 2018) and as a duo with saxophone. In this video, shadow was played as one movement of a longer performance on the Frequency Series at Constellation in Chicago.
The sounds of the no-input mixer are analyzed in real-time using timbral descriptors, which are then sent to a neural network for classification into one of four categories: distorted noise, high squeal, low impulses, or quiet sustained noise.</description></item><item><title>tap</title><link>https://tedmoore.github.io/works/tap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tedmoore.github.io/works/tap/</guid><description>Commissioned by line upon line percussion
recorded at UT Austin, January 12, 2019
Composing tap began by recording many sounds, gestures, and passages on my eurorack modular synthesizer and then organizing these recordings into a tape part for the piece. I then transcribed the rhythms and timbres of the tape part to create a tight synchronization between the the tape and percussion parts played by the ensemble. The video and lights were then composed to add to the intense synchrony.</description></item></channel></rss>